{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7faf47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T16:11:58.015866Z",
     "iopub.status.busy": "2023-03-05T16:11:58.014586Z",
     "iopub.status.idle": "2023-03-05T19:15:42.683653Z",
     "shell.execute_reply": "2023-03-05T19:15:42.682451Z"
    },
    "papermill": {
     "duration": 11024.676298,
     "end_time": "2023-03-05T19:15:42.686647",
     "exception": false,
     "start_time": "2023-03-05T16:11:58.010349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█████| 570/570 [00:00<00:00, 66.2kB/s]\r\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███| 213k/213k [00:00<00:00, 2.37MB/s]\r\n",
      "Downloading (…)okenizer_config.json: 100%|███| 29.0/29.0 [00:00<00:00, 10.6kB/s]\r\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|███| 436M/436M [00:15<00:00, 28.7MB/s]\r\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\r\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Downloading (…)lve/main/config.json: 100%|██████| 503/503 [00:00<00:00, 186kB/s]\r\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|███| 436M/436M [00:15<00:00, 28.5MB/s]\r\n",
      "Some weights of the model checkpoint at razent/spbert-mlm-zero were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\r\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Some weights of BertModel were not initialized from the model checkpoint at razent/spbert-mlm-zero and are newly initialized: ['bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\r\n",
      "  FutureWarning,\r\n",
      "  0%|                                                   | 0/125 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "epoch 0 loss 7.1987: 100%|████████████████████| 125/125 [02:03<00:00,  1.01it/s]\r\n",
      "finished\r\n",
      "epoch 1 loss 5.1197: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 2 loss 4.2384: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 3 loss 3.7564: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 4 loss 3.4455: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 5 loss 3.2229: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 6 loss 3.0515: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 7 loss 2.9134: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 8 loss 2.7985: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 9 loss 2.7007: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 10 loss 2.6161: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 11 loss 2.5419: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 12 loss 2.476: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 13 loss 2.417: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 14 loss 2.3636: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "starting evaluation\r\n",
      "we are in the else condition\r\n",
      "before eval_sampler\r\n",
      "before batch_eval_dataloader\r\n",
      "before train\r\n",
      "ECCOCI\r\n",
      "/kaggle/working/checkpoint-best-bleu/pytorch_model.bin\r\n",
      "epoch 15 loss 1.5875: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 16 loss 1.5737: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 17 loss 1.5612: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 18 loss 1.5497: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 19 loss 1.5389: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 20 loss 1.5291: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 21 loss 1.52: 100%|█████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 22 loss 1.5116: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 23 loss 1.5037: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 24 loss 1.4965: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 25 loss 1.4899: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 26 loss 1.4838: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 27 loss 1.4781: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 28 loss 1.4729: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 29 loss 1.4681: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "starting evaluation\r\n",
      "before eval_sampler\r\n",
      "before batch_eval_dataloader\r\n",
      "before train\r\n",
      "ECCOCI\r\n",
      "/kaggle/working/checkpoint-best-bleu/pytorch_model.bin\r\n",
      "epoch 30 loss 1.3967: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 31 loss 1.3946: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 32 loss 1.393: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 33 loss 1.3916: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 34 loss 1.3903: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 35 loss 1.3891: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 36 loss 1.388: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 37 loss 1.387: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 38 loss 1.386: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 39 loss 1.3851: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 40 loss 1.3843: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 41 loss 1.3835: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 42 loss 1.3828: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 43 loss 1.3821: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 44 loss 1.3814: 100%|███████████████████| 125/125 [02:00<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "starting evaluation\r\n",
      "before eval_sampler\r\n",
      "before batch_eval_dataloader\r\n",
      "before train\r\n",
      "ECCOCI\r\n",
      "/kaggle/working/checkpoint-best-bleu/pytorch_model.bin\r\n",
      "epoch 45 loss 1.372: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 46 loss 1.3716: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 47 loss 1.3712: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 48 loss 1.3709: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 49 loss 1.3707: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 50 loss 1.3704: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 51 loss 1.3702: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 52 loss 1.37: 100%|█████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 53 loss 1.3698: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 54 loss 1.3696: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 55 loss 1.3694: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 56 loss 1.3692: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 57 loss 1.3691: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 58 loss 1.369: 100%|████████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "epoch 59 loss 1.3688: 100%|███████████████████| 125/125 [02:01<00:00,  1.03it/s]\r\n",
      "finished\r\n",
      "starting evaluation\r\n",
      "before eval_sampler\r\n",
      "before batch_eval_dataloader\r\n",
      "before train\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/spbert-attempt/spbert-main/run.py --do_train --do_eval --model_type bert --model_architecture bert2bert --encoder_model_name_or_path bert-base-cased --decoder_model_name_or_path razent/spbert-mlm-zero --source sparql --target en --train_filename /kaggle/input/spbert-attempt/spbert-main/LCQUAD/train --dev_filename /kaggle/input/spbert-attempt/spbert-main/LCQUAD/dev --output_dir /kaggle/working --max_source_length 64 --weight_decay 0.01 --max_target_length 128 --beam_size 10 --train_batch_size 32 --eval_batch_size 32 --learning_rate 5e-5 --save_inverval 15 --num_train_epochs 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5949e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T19:15:44.350678Z",
     "iopub.status.busy": "2023-03-05T19:15:44.350282Z",
     "iopub.status.idle": "2023-03-05T19:46:41.015512Z",
     "shell.execute_reply": "2023-03-05T19:46:41.014280Z"
    },
    "papermill": {
     "duration": 1857.528159,
     "end_time": "2023-03-05T19:46:41.018282",
     "exception": false,
     "start_time": "2023-03-05T19:15:43.490123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\r\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Some weights of the model checkpoint at razent/spbert-mlm-zero were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\r\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Some weights of BertModel were not initialized from the model checkpoint at razent/spbert-mlm-zero and are newly initialized: ['bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "100%|███████████████████████████████████████████| 16/16 [14:53<00:00, 55.82s/it]\r\n",
      "100%|███████████████████████████████████████████| 16/16 [15:43<00:00, 58.95s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/spbert-attempt/spbert-main/run.py --do_test --model_type bert --model_architecture bert2bert --encoder_model_name_or_path bert-base-cased --decoder_model_name_or_path razent/spbert-mlm-zero --source sparql --target en --load_model_path /kaggle/working/checkpoint-best-bleu/pytorch_model.bin --dev_filename /kaggle/input/spbert-attempt/spbert-main/LCQUAD/dev --test_filename /kaggle/input/spbert-attempt/spbert-main/LCQUAD/test --output_dir /kaggle/working --max_source_length 64 --max_target_length 128 --beam_size 10 --eval_batch_size 32 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12897.57051,
   "end_time": "2023-03-05T19:46:42.479405",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-05T16:11:44.908895",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
